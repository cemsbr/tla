\documentclass[brazil, a4paper,12pt]{article}
\usepackage[brazil]{babel}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage[usenames]{color}
\usepackage{ae,amsfonts,amsmath,amssymb,colortbl,keyval,lscape,paralist,
            xspace,setspace,subfigure,tabularx,times,listings,lettrine,
            pdftricks,textfit,titlesec,fancyhdr}
\geometry{a4paper,left=3cm,right=3cm,top=2.5cm,bottom=2.5cm}
\lstset{language=Java, tabsize=4, stringstyle=\ttfamily,basicstyle=\ttfamily, showstringspaces=false}

\begin{document}
\begin{titlepage}

  \vfill

  \begin{center}
    \begin{large}
      Universidade de São Paulo
    \end{large}
  \end{center}

  \begin{center}
    \begin{large}
      Instituto de Matemática e Estatística
    \end{large}
  \end{center}

  \begin{center}
    \begin{large}
      Programa de Pós-Graduação em Ciência da Computação
    \end{large}
  \end{center}

  \vfill

  \begin{center}
    \begin{Large}
        \textbf{MAC0431}\\
        \textbf{Introdução à Computação Paralela e Distribuída}\\
          Segundo Exercício Programa\\
    \end{Large}
  \end{center}

  \vfill

  \begin{center}
    \begin{large}
      Carlos Eduardo Moreira dos Santos\\
      Thiago Furtado de Mendonça
    \end{large}
  \end{center}

  \begin{center}
    \begin{large}
      Professor - Alfredo Goldman\\
    \end{large}
  \end{center}

  \vfill

  \begin{center}
    \begin{large}
      São Paulo \\
      \today \\
    \end{large}
  \end{center}

\clearpage
\tableofcontents 
\end{titlepage}

\section{Introdução}

Este trabalho visa analisar logs de servidores web e gerar dados para montar
gráficos como o da Figura~\ref{fig:portal}. Ele mostra a média do tempo de
resposta de um serviço conforme o número de clientes simultâneos aumenta. Um
intervalo de confiança de 95\% também foi calculado para cada média, mas não é
mostrado por ser muito pequeno neste caso.

A Figura~\ref{fig:portal} usou dados obtidos atráves de um gerador de carga
sobre o serviço \emph{Portal} (a ser detalhado em \ref{sec:fmarket}). Além
desse serviço, desejamos analisar o desempenho de todos os outros envolvidos na
composição. Isso é possível através da análise dos logs de cada servidor, e o
Hadoop nos ajudará a processar os 200 GB de logs do experimento executado.

\begin{figure}[!ht]
  \begin{center}
    \includegraphics[width=\linewidth,clip=true,trim=1mm 6mm 3mm 20mm]{../talk/figures/portals1-4}
  \caption{Tempo médio de resposta do serviço \emph{Portal}.}
  \end{center}
  \label{fig:portal}
\end{figure}

\subsection{Caso de Uso}
\label{sec:fmarket}

O experimento utilizou a composição de serviços
\href{http://github.com/choreos/future_market_choreography/}{Future Market},
escrita em java e implantanda em Apache Tomcat, sendo um serviço por máquina.
Resumidamente, o gerador de carga simula um cliente que deseja comprar uma
lista de produtos nos supermercados que oferecem o menor preço para cada um
deles. Além dos supermercados, existem outros serviços como banco, fornecedor,
  fabricante, entrega de pacotes e registro de serviços.

Existem mais de uma instância de um determinado serviço, podendo haver até 17
no total em nosso experimento (em 17 servidores diferentes). Em particular,
   estamos interessados em comparar dois tipos de composição: orquestração e
   coreografia. No primeiro tipo, os serviços comunicam-se uns com os outros
   por intermédio do serviço \emph{Portal}, como podemos ver na
   Figura~\ref{fig:orch}. Já na coreografia, os serviços se comunicam
   diretamente, como na Figura~\ref{fig:chor}. 

\begin{figure}
  \begin{center}
    \includegraphics[width=\textwidth,clip=true,trim=7mm 9mm 8mm 16mm]{../talk/figures/orch}
    \caption{Interação entre serviços na versão com orquestração.}
    \label{fig:orch}
  \end{center}
\end{figure}

\begin{figure}
  \begin{center}
    \includegraphics[width=\textwidth,clip=true,trim=2mm 10mm 5mm 14mm]{../talk/figures/chor}
    \caption{Interação entre serviços na versão com coreografia.}
    \label{fig:chor}
  \end{center}
\end{figure}

\section{Dados de Entrada}

\subsection{Gerador de Carga}
O gerador de carga desenvolvido para o \emph{Portal} produz um log no seguinte
formato:

\begin{verbatim}
# orch,1,50,1349926295888
424
892
(...)
2017
2038
# orch,1,100,1349926297945
1110
1189
(...)
\end{verbatim}

As linhas que iniciam com \verb/#/ possuem a seguinte semântica:\\

\begin{tabular}{r l}
  {\bf orch,1} & Arquitetura (orquestração, {\bf1} portal)\\
  {\bf 50/100} & Número de clientes simultâneos (eixo x)\\
  {\bf 134552629...} & Instante da execução, em milissegundos
\end{tabular}
\\

Em seguida, os tempos de resposta são registrados um por linha, totalizando $n$
registros, onde $n$ é o número de clientes simultâneos. A simulação contém mais
de uma ocorrência para uma dada arquitetura e número de clientes simultâneos.

\subsection{Log}
  O formato do log do Apache Tomcat foi modificado, possuindo um campo a mais
  que o padão no final, correspondente ao tempo de processamento da requisição.
  Como exemplo, temos a linha:

\begin{verbatim}
198.55.32.149 - - [09/Oct/2012:02:47:56 -0700] "POST
/supermarket5/orchestration HTTP/1.1" 200 914 811
\end{verbatim}

Neste exemplo, a requisição ao serviço \emph{Supermarket} de número 5 na
orquestração demorou 811 milissegundos para ser processada. Note que não há
como inferir, somente por esta linha, quantos clientes simultâneos estavam
acessando o portal neste momento, assim como outras características da
arquitetura (número de portais).

\section{Hadoop}

Foi utilizado MapReduce através do Apache Hadoop para calcular médias e desvios
padrão por tipo de experimento num total de 200 GB de dados. Um tipo de
experimento é determinado pelo tipo de composição, número de portais e pela
quantidade de clientes simultâneos. Os códigos das funções \emph{Map} e
\emph{Reduce} são apresentados nas próximas subseções.

\subsection{Map}

Nesta fase, foi gerado como chave e um identificador para o serviço (ex.:
    \emph{supermarket5}, \emph{bank}) e o tipo de experimento. Para tal, foi
necessário fazer a corespondência entre o tempo da requisição registrado no
servidor web e o tipo de experimento em andamento no gerador de carga. Essa
correspondência foi feita usando os \emph{parsers} \emph{TomcatLogParser} e
\emph{ExperimentLogParser}.

Para um entrada da função \emph{map}, ou seja, uma linha do \emph{log} do
Apache Tomcat, o \emph{TomcatLogParser} permite recuperar data da requisição,
       nome do serviço destino da requisição e o tempo de resposta despendido,
       através dos métodos \emph{getDate()}, \emph{getServiceName()} e
       \emph{getResponseTime()}, respectivamente. Com isso, o tipo do
       experimento que gerou o registro no \emph{log} do Apache Tomcat pode ser
       recuperado pelo \emph{ExperimentLogParser} passando para o método
       \emph{getType(long time)} o instante em milissegundos em que a
       requisição foi gerada. Assim, o \emph{map} associa a chave representando
       o experimento com o valor do tempo gasto para processá-lo (ex.:\\ a
           cadeia \verb|"/choreography/bank,chor,2,100"| é chave para \verb|25|
           se o serviço\\ \verb|/choreography/bank| no experimento
           \verb|chor,2,100| gastou \verb|25| milissegundos para responder).
       Para economizar memória e processamento, os dados do log do experimento
       são compartilhados entre os objetos da classe \emph{ExperimentLogParser}
       através de atributos estáticos cujas atribuições são realizadas no
       construtor, dentro de um bloco sincronizado (palavra-chave
           \emph{synchronized} da linguagem Java).

Abaixo pode ser vista a implementação da função \emph{map}. Na linha 4 é feita
a verificação quanto à pertinência do registro ao experimento. Nas linhas de 9
a 11 são recuperados data, nome do serviço e tempo de resposta da requisição.
Na linha 12 é feita a correspondência da requisição com o tipo de experimento.
Nas linhas 14 e 15 é atribuído conteúdo para a chave e valor que serão
escritos. Finalmente, na linha 16 é escrita a saída da função.

\begin{figure} [!htb]
\begin{center}
\footnotesize
\begin{lstlisting}[numbers=left]
public void map(final Object key, final Text value,
		final Context context) throws IOException, InterruptedException {
	final String tomcatLine = value.toString();
	if (!tomcatParser.setLine(tomcatLine)) {
		return;
	}

	try {
		date = tomcatParser.getDate();
		service = tomcatParser.getServiceName();
		responseTime = tomcatParser.getResponseTime();
		type = expParser.getType(date.getTime());

		lineKey.set(service + "," + type);
		lineValue.set(responseTime);
		context.write(lineKey, lineValue);
	} catch (ParseException e) {
		e.printStackTrace();
	} catch (ExperimentNotFoundException e) {
		e.printStackTrace();
	}
}
\end{lstlisting}
\end{center}
\caption{Função \emph{map} do objeto \emph{Mapper}}
\end{figure}

% Detailed explanation line by line of map funciton

\subsection{Reduce} A função \emph{Reduce} recebe, para cada tipo de
experimento (chave), inúmeros tempos de resposta.  Seu trabalho é o de resumir
os dados em média e intervalo de confiança (necessário o cálculo do desvio
    padrão). Para isso a classe \emph{Statistics} provê funções para os devidos
cálculos.

Abaixo, a implementação da função \emph{reduce} do objeto \emph{Reducer}. Nas
linhas 6 e 7, cada valor associado a um experimento é adicionado ao objeto
\verb|stats| para o cálculo da média e do intervalo de confiança. Por fim, na
linha 13, são concatenados a média e o intervalo de confiança  e, na linha 14,
      o resultado é escrito no arquivo final.

\begin{figure} [!htb]
\begin{center}
\footnotesize
\begin{lstlisting} [numbers=left]
public void reduce(Text key, Iterable<IntWritable> values,
		Context context) throws IOException, InterruptedException {

	final Statistics stats = new Statistics();

	for (IntWritable value : values) {
		stats.addValue(value.get());
	}

	final double mean = stats.getMean();
	final double confInterval = stats.getCI();

	result.set("" + mean + "," + confInterval);
	context.write(key, result);
}
\end{lstlisting}
\end{center}
\caption{Função \emph{reduce} do objeto \emph{Reducer}}
\end{figure}

\subsection {HDFS}

Pelo fato do log do experimento ser utlizado por todos os \emph{mappers}, mais
expecificamente pela classe \verb|ExperimentLogParser|, utilizamos a classe
\verb|DistributedCache| para otimizar a distribuição do arquivo para todos os
nós.

\subsection {Dificuldades}

\subsubsection{Configuração do Hadoop}

A configuração do modo pseudo-distribuído não foi fácil como parece no tutorial
oficial. O sistema operacional não estava configurado para IPv6 e as mensagens
de erro não ajudaram a detectar o problema. Após horas de depuração e pesquisa,
   a solução foi encontrada no fórum da disciplina. A preferência a IPv4 foi
   configurada no Java e tudo funcionou corretamente.

\subsubsection{\emph{Overflow}}

É importante notar que não é possível obter a quantidade de valores sem antes
percorrer todo o iterador, nem reiniciá-lo após chegar ao seu fim. Essas
características dificultam o cálculo da média e do desvio padrão. Sem os
devidos cuidados, a soma de $n$ elementos pode estourar o tipo primitivo.

Para contornar evitar \emph{overflow} no cálculo da média, ao invés de somar
todos os valores e fazer uma só divisão no final, atualizamos a média
\emph{mean} após cada valor adicionado ao objeto da classe \emph{Statistics}
seguindo a fórmula

\[ mean = mean \times \frac{size-1}{size} + \frac{value}{size} \]

\noindent sendo \emph{size} a quantidade de valores da amostra parcial e
\emph{value} o último valor a ser adicionado nela.

Solução análoga foi aplicada ao cálculo do desvio padrão, com a diferença de
que a média é um pré-requisito para calculá-lo, motivo pelo qual armazenamos
todos os valores em um atributo antes de usar o algoritmo da
Figura~\ref{fig:stddev}.

\begin{figure} [!htb] \begin{center} \footnotesize
\begin{lstlisting}[numbers=left]
public double getStdDev() {
    double variance = 0;
    for (Integer value : values) {
      variance += ((value - mean) * (value - mean)) / (values.size() - 1);
    }
    return Math.sqrt(variance);
  }\end{lstlisting}
\end{center}
\caption{Cálculo do desvio padrão evitando \emph{overflow}.}
\label{fig:stddev}
\end{figure}

\subsubsection{Velocidade do Processamento}

Para testar a aplicação, utilizamos dois logs de 1,3 MB: o do experimento e o
do Tomcat, sendo o tamanho do último após compressão por \emph{bzip2}. O Hadoop
foi configurado no modo \emph{stand-alone} para os testes. A primeira versão
ficou lenta, demorando cerca de 30 minutos. Numa segunda versão, o tempo caiu
para 3 minutos ao utilizarmos a classe \verb|Pattern| do Java. Após outras
otimizações, como a busca binária da data no log do experimento, a última
versão foi executada em cerca de 30 segundos. Os tempos de execução foram
tomados em um MacBook Pro com processador Pentium i7 de dois núcleos com 2.7GHz
e HT.

\subsection{Facilidades}

\subsubsection{Java}

A familiaridade com a linguagem Java nos ajudou, em especial nas otimizações
que aceleraram a execução em mais de 60 vezes. Fizemos testes com JUnit e
encontramos rapidamente um \emph{archetype} para o
\href{http://maven.apache.org/}{Maven}, facilitando a desenvolvimento.

\subsubsection{Abstração}

Não foi necessária a preocupação com o gerenciamento de um sistema
distribuído.  O Hadoop abstrai toda a comunicação, distribuição de dados e
computação, assim como o mascaramento de falhas. Além disso, não precisamos de
um conjunto de computadores para testar a implementação, pois a configuração
pseudo-distribuída nos ajudou a simular com boa semelhança um caso
verdadeiramente distribuído.

\section {Executando}

Seguem instruções para executar o Tomcat Log Analyser no modo
pseudo-distribuído com os arquivos de exemplo entregues. O mesmo deve valer
para o modo verdadeiramente distribuído. São assumidas as seguintes
configurações (as variáveis de ambiente são ilustrativas e não necessárias para
    o funcionamento correto do programa):

\begin{enumerate}
  \item \$TLA é o diretório raiz do arquivo entregue para correção
  \item \$HADOOP corresponde à pasta onde o Hadoop está instalado
  \item Hadoop configurado \end{enumerate}

\subsection {Jar Fornecido}

O pacote entregue inclui uma compilação por Java 7 com compatibilidade com Java
6.

\begin{verbatim}
# Copiando arquivos de entrada para o HDFS:
$ cd $HADOOP
$ bin/hadoop fs -mkdir tla-input
$ bin/hadoop fs -copyFromLocal $TLA/files/* tla-input/
# Executando o programa:
$ bin/hadoop jar $TLA/bin/tla-1.0-job.jar \
tla-input/filtered_log tla-input/input_path tla-output
# Copiando a saída do HDFS:
bin/hadoop fs -get tla-output tla-output
\end{verbatim}

O resultado da execução será encontrado na pasta \verb|tla-output|.

\subsection {Testes e Compilação}

Para executar os testes da aplicação e compilá-la, gerando
\verb|target/tla-1.0-job.jar| é necessário o software Maven 3 e os seguintes
comandos:

\begin{verbatim}
$ cd $TLA
$ mvn package
\end{verbatim}

\section {Conclusão}

Considerando que a análise de comportamento de sistemas distribuídos não é
trivial, o trabalho mostrou a facilidade que o arcabouço pode proporcionar
nessa análise considerando arquivos com registro de eventos do sistema. A
correlação entre o tipo de experimento realizado e o registro da resposta a
cada requisição foi resolvida ao configurar um \emph{Mapper} que a fizesse.
Para gerar dados estatísticos, a configuração do \emph{Reducer} gera uma saída
formatada que é rapida e facilmente lida por outros aplicativos que geram
gráficos (ex.: os programas \textit{open source}
    \href{http://www.r-project.org/}{R} e
    \href{http://www.gnuplot.info/}{GnuPlot}).

Algumas dificuldades foram encontradas, mas todas, superadas. O trabalho
resultante será utilizado para nossas pesquisas e publicado sob licença livre.

\end{document}

% vim: set tw=80 fo=cat:
